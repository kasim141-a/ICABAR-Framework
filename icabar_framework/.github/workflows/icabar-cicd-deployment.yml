name: ICABAR Framework CI/CD with Deployment

on:
  push:
    branches: [ main, develop ]
    tags:
      - 'v*.*.*'
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.8'
  COVERAGE_THRESHOLD: 90
  PERFORMANCE_TARGET_MS: 47.0
  DOCKER_REGISTRY: ghcr.io
  IMAGE_NAME: icabar/framework

jobs:
  # Code Quality and Linting
  code-quality:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install linting dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy
        
    - name: Run Black formatter check
      run: |
        black --check --diff icabar_framework/
        
    - name: Run isort import sorting check
      run: |
        isort --check-only --diff icabar_framework/
        
    - name: Run flake8 linting
      run: |
        flake8 icabar_framework/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 icabar_framework/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Run mypy type checking
      run: |
        mypy icabar_framework/ --ignore-missing-imports || true

  # Unit Tests and Coverage Analysis
  test-and-coverage:
    name: Unit Tests & Coverage
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install coverage pytest pytest-cov
        
    - name: Run unit tests with coverage
      run: |
        coverage run --source=icabar_framework -m unittest discover -s icabar_framework/tests -p "test_*.py" -v
        
    - name: Generate coverage report
      run: |
        coverage report -m --fail-under=${{ env.COVERAGE_THRESHOLD }}
        coverage xml
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false
        
    - name: Store coverage report
      uses: actions/upload-artifact@v3
      with:
        name: coverage-report-${{ matrix.python-version }}
        path: |
          coverage.xml
          .coverage

  # Performance Benchmarking
  performance-benchmark:
    name: Performance Benchmark
    runs-on: ubuntu-latest
    needs: test-and-coverage
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/tags/')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install psutil memory_profiler
        
    - name: Run performance benchmark
      id: benchmark
      run: |
        echo "Running performance benchmark..."
        python icabar_framework/scripts/performance_benchmark.py > benchmark_results.txt 2>&1
        cat benchmark_results.txt
        
        AVG_LATENCY=$(grep -o 'Average latency: [0-9.]*' benchmark_results.txt | grep -o '[0-9.]*' || echo "0")
        MAX_MEMORY=$(grep -o 'Peak memory usage: [0-9.]*' benchmark_results.txt | grep -o '[0-9.]*' || echo "0")
        
        echo "avg_latency=$AVG_LATENCY" >> $GITHUB_OUTPUT
        echo "max_memory=$MAX_MEMORY" >> $GITHUB_OUTPUT
        
    - name: Validate performance targets
      run: |
        AVG_LATENCY=${{ steps.benchmark.outputs.avg_latency }}
        
        echo "Average latency: ${AVG_LATENCY}ms (target: <${{ env.PERFORMANCE_TARGET_MS }}ms)"
        
        if (( $(echo "$AVG_LATENCY > ${{ env.PERFORMANCE_TARGET_MS }}" | bc -l) )); then
          echo "::error::Performance target not met! Average latency was ${AVG_LATENCY}ms, target is <${{ env.PERFORMANCE_TARGET_MS }}ms"
          exit 1
        else
          echo "‚úÖ Performance target met: ${AVG_LATENCY}ms < ${{ env.PERFORMANCE_TARGET_MS }}ms"
        fi
        
    - name: Store benchmark results
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: benchmark_results.txt

  # Research Validation
  research-validation:
    name: Research Claims Validation
    runs-on: ubuntu-latest
    needs: test-and-coverage
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/tags/')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install scipy statsmodels
        
    - name: Run research validation
      id: validation
      run: |
        echo "Running research validation..."
        python icabar_framework/scripts/research_validation.py > validation_results.txt 2>&1
        cat validation_results.txt
        
        if grep -q "VALIDATION FAILED" validation_results.txt; then
          echo "validation_status=FAILED" >> $GITHUB_OUTPUT
        else
          echo "validation_status=PASSED" >> $GITHUB_OUTPUT
        fi
        
    - name: Validate research claims
      run: |
        VALIDATION_STATUS=${{ steps.validation.outputs.validation_status }}
        
        if [ "$VALIDATION_STATUS" = "FAILED" ]; then
          echo "::error::Research validation failed. Framework does not meet claimed performance improvements."
          exit 1
        else
          echo "‚úÖ All research claims validated successfully"
        fi
        
    - name: Store validation results
      uses: actions/upload-artifact@v3
      with:
        name: validation-results
        path: validation_results.txt

  # Security Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    if: github.event_name == 'push' || github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Run Bandit security scan
      uses: securecodewarrior/github-action-bandit@v1
      with:
        path: icabar_framework/
        
    - name: Run Safety dependency scan
      run: |
        pip install safety
        safety check --json || true

  # Build Docker Image
  build-image:
    name: Build Docker Image
    runs-on: ubuntu-latest
    needs: [test-and-coverage, performance-benchmark, research-validation]
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/develop' || startsWith(github.ref, 'refs/tags/')
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.DOCKER_REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-
          
    - name: Build and push Docker image
      id: build
      uses: docker/build-push-action@v5
      with:
        context: .
        platforms: linux/amd64,linux/arm64
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Generate SBOM
      uses: anchore/sbom-action@v0
      with:
        image: ${{ steps.meta.outputs.tags }}
        format: spdx-json
        output-file: sbom.spdx.json
        
    - name: Store SBOM
      uses: actions/upload-artifact@v3
      with:
        name: sbom
        path: sbom.spdx.json

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-image]
    if: github.ref == 'refs/heads/develop'
    environment:
      name: staging
      url: https://staging.icabar.example.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_STAGING }}
        
    - name: Deploy to staging
      run: |
        # Replace image tag in deployment configuration
        sed -i "s|icabar/framework:staging-.*|${{ needs.build-image.outputs.image-tag }}|g" deployment/environments/staging.yml
        
        # Apply deployment
        kubectl apply -f deployment/environments/staging.yml
        
        # Wait for rollout to complete
        kubectl rollout status deployment/icabar-staging -n icabar-staging --timeout=300s
        
    - name: Run staging smoke tests
      run: |
        # Wait for service to be ready
        sleep 30
        
        # Get service endpoint
        STAGING_URL=$(kubectl get service icabar-staging-service -n icabar-staging -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        
        # Run smoke tests
        curl -f "http://${STAGING_URL}/health" || exit 1
        curl -f "http://${STAGING_URL}:8080/metrics" || exit 1
        
        echo "‚úÖ Staging deployment successful"
        
    - name: Notify staging deployment
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: 'Staging deployment ${{ job.status }} for commit ${{ github.sha }}'
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Deploy to Production (Manual Approval Required)
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-image, deploy-staging]
    if: startsWith(github.ref, 'refs/tags/')
    environment:
      name: production
      url: https://api.icabar.example.com
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}
        
    - name: Pre-deployment validation
      run: |
        echo "üîç Running pre-deployment validation..."
        
        # Validate image exists
        docker manifest inspect ${{ needs.build-image.outputs.image-tag }}
        
        # Check cluster health
        kubectl cluster-info
        kubectl get nodes
        
        # Validate namespace
        kubectl get namespace icabar-production || kubectl create namespace icabar-production
        
        echo "‚úÖ Pre-deployment validation passed"
        
    - name: Deploy canary to production
      id: canary
      run: |
        echo "üöÄ Starting canary deployment..."
        
        # Create canary deployment configuration
        cp deployment/environments/production.yml /tmp/canary-deployment.yml
        sed -i 's/icabar-production/icabar-production-canary/g' /tmp/canary-deployment.yml
        sed -i 's/replicas: 5/replicas: 1/g' /tmp/canary-deployment.yml
        sed -i "s|icabar/framework:.*|${{ needs.build-image.outputs.image-tag }}|g" /tmp/canary-deployment.yml
        
        # Deploy canary
        kubectl apply -f /tmp/canary-deployment.yml
        
        # Wait for canary to be ready
        kubectl rollout status deployment/icabar-production-canary -n icabar-production --timeout=300s
        
        echo "canary_deployed=true" >> $GITHUB_OUTPUT
        
    - name: Monitor canary deployment
      run: |
        echo "üìä Monitoring canary deployment for 5 minutes..."
        
        # Monitor for 5 minutes
        for i in {1..10}; do
          echo "Monitoring iteration $i/10..."
          
          # Check pod health
          CANARY_POD=$(kubectl get pods -n icabar-production -l app=icabar-production-canary -o jsonpath='{.items[0].metadata.name}')
          POD_STATUS=$(kubectl get pod "$CANARY_POD" -n icabar-production -o jsonpath='{.status.phase}')
          
          if [[ "$POD_STATUS" != "Running" ]]; then
            echo "::error::Canary pod not running: $POD_STATUS"
            exit 1
          fi
          
          # Check health endpoint
          kubectl exec "$CANARY_POD" -n icabar-production -- curl -f http://localhost:8000/health || exit 1
          
          # Check performance metrics
          METRICS=$(kubectl exec "$CANARY_POD" -n icabar-production -- curl -s http://localhost:8080/metrics)
          echo "Canary metrics: $METRICS"
          
          sleep 30
        done
        
        echo "‚úÖ Canary monitoring completed successfully"
        
    - name: Full production deployment
      run: |
        echo "üöÄ Starting full production deployment..."
        
        # Update production deployment
        sed -i "s|icabar/framework:.*|${{ needs.build-image.outputs.image-tag }}|g" deployment/environments/production.yml
        
        # Apply production deployment
        kubectl apply -f deployment/environments/production.yml
        
        # Wait for rollout to complete
        kubectl rollout status deployment/icabar-production -n icabar-production --timeout=600s
        
        # Clean up canary deployment
        kubectl delete -f /tmp/canary-deployment.yml || true
        
        echo "‚úÖ Production deployment completed"
        
    - name: Post-deployment validation
      run: |
        echo "üîç Running post-deployment validation..."
        
        # Wait for service to stabilize
        sleep 60
        
        # Get production service endpoint
        PROD_URL=$(kubectl get service icabar-production-service -n icabar-production -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        
        # Run comprehensive health checks
        curl -f "http://${PROD_URL}/health" || exit 1
        curl -f "http://${PROD_URL}:8080/metrics" || exit 1
        
        # Validate performance
        RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}' "http://${PROD_URL}/health")
        if (( $(echo "$RESPONSE_TIME > 0.1" | bc -l) )); then
          echo "::warning::Response time higher than expected: ${RESPONSE_TIME}s"
        fi
        
        # Check all pods are running
        kubectl get pods -n icabar-production -l app=icabar-production
        
        echo "‚úÖ Post-deployment validation passed"
        
    - name: Update deployment status
      run: |
        echo "üìù Updating deployment status..."
        
        # Create deployment record
        kubectl annotate deployment icabar-production -n icabar-production \
          deployment.kubernetes.io/revision="$(date +%s)" \
          deployment.icabar.io/version="${{ github.ref_name }}" \
          deployment.icabar.io/commit="${{ github.sha }}" \
          deployment.icabar.io/deployed-by="${{ github.actor }}" \
          deployment.icabar.io/deployed-at="$(date -u +%Y-%m-%dT%H:%M:%SZ)"
        
    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: |
          üöÄ Production deployment ${{ job.status }}
          Version: ${{ github.ref_name }}
          Commit: ${{ github.sha }}
          Deployed by: ${{ github.actor }}
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Rollback Production (Manual Trigger)
  rollback-production:
    name: Rollback Production
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'
    environment:
      name: production-rollback
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}
        
    - name: Rollback production deployment
      run: |
        echo "‚è™ Rolling back production deployment..."
        
        # Get current revision
        CURRENT_REVISION=$(kubectl rollout history deployment/icabar-production -n icabar-production --revision=0 | tail -1 | awk '{print $1}')
        echo "Current revision: $CURRENT_REVISION"
        
        # Rollback to previous revision
        kubectl rollout undo deployment/icabar-production -n icabar-production
        
        # Wait for rollback to complete
        kubectl rollout status deployment/icabar-production -n icabar-production --timeout=300s
        
        echo "‚úÖ Rollback completed"
        
    - name: Validate rollback
      run: |
        echo "üîç Validating rollback..."
        
        # Wait for service to stabilize
        sleep 30
        
        # Get service endpoint
        PROD_URL=$(kubectl get service icabar-production-service -n icabar-production -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        
        # Run health checks
        curl -f "http://${PROD_URL}/health" || exit 1
        curl -f "http://${PROD_URL}:8080/metrics" || exit 1
        
        echo "‚úÖ Rollback validation passed"
        
    - name: Notify rollback
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        text: |
          ‚è™ Production rollback ${{ job.status }}
          Triggered by: ${{ github.actor }}
          Reason: Manual rollback requested
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  # Build Package (for PyPI)
  build-package:
    name: Build Package
    runs-on: ubuntu-latest
    needs: [test-and-coverage, performance-benchmark, research-validation]
    if: startsWith(github.ref, 'refs/tags/')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build setuptools wheel twine
        
    - name: Build package
      run: |
        python -m build
        
    - name: Check package
      run: |
        twine check dist/*
        
    - name: Store package artifacts
      uses: actions/upload-artifact@v3
      with:
        name: python-package
        path: dist/

  # Publish to PyPI
  publish-pypi:
    name: Publish to PyPI
    runs-on: ubuntu-latest
    needs: [build-package, deploy-production]
    if: startsWith(github.ref, 'refs/tags/')
    environment:
      name: pypi
      url: https://pypi.org/p/icabar-framework
    permissions:
      id-token: write
      
    steps:
    - name: Download package artifacts
      uses: actions/download-artifact@v3
      with:
        name: python-package
        path: dist/
        
    - name: Publish to PyPI
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        packages-dir: dist/

  # Create GitHub Release
  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [publish-pypi, deploy-production]
    if: startsWith(github.ref, 'refs/tags/')
    permissions:
      contents: write
      
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Download all artifacts
      uses: actions/download-artifact@v3
      
    - name: Create Release
      uses: softprops/action-gh-release@v1
      with:
        files: |
          python-package/*
          benchmark-results/*
          validation-results/*
          sbom/*
        body: |
          ## üöÄ ICABAR Framework Release ${{ github.ref_name }}
          
          ### ‚ú® What's New
          - ‚úÖ Performance validated: Average latency < 47ms
          - ‚úÖ Research claims verified: 33% accuracy, 65% diversity, 45% novelty improvements
          - ‚úÖ Comprehensive test coverage: >90%
          - ‚úÖ Security scanned and validated
          - ‚úÖ Successfully deployed to production
          
          ### üì¶ Installation
          ```bash
          pip install icabar-framework==${{ github.ref_name }}
          ```
          
          ### üîß Docker Image
          ```bash
          docker pull ${{ env.DOCKER_REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.ref_name }}
          ```
          
          ### üìä Performance Metrics
          See attached benchmark results for detailed performance analysis.
          
          ### üî¨ Research Validation
          See attached validation results for research claim verification.
          
          ### üõ°Ô∏è Security
          See attached SBOM (Software Bill of Materials) for security analysis.
          
          ### üöÄ Deployment Status
          - ‚úÖ Staging: Deployed and validated
          - ‚úÖ Production: Deployed with canary strategy
          - ‚úÖ PyPI: Package published
          
          ---
          **Full Changelog**: https://github.com/${{ github.repository }}/compare/${{ github.event.before }}...${{ github.ref_name }}
        draft: false
        prerelease: false
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Deployment Summary
  deployment-summary:
    name: Deployment Summary
    runs-on: ubuntu-latest
    needs: [code-quality, test-and-coverage, performance-benchmark, research-validation, security-scan, build-image, deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Generate deployment summary
      run: |
        echo "## üöÄ ICABAR Framework CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Component | Status | Details |" >> $GITHUB_STEP_SUMMARY
        echo "|-----------|--------|---------|" >> $GITHUB_STEP_SUMMARY
        echo "| Code Quality | ${{ needs.code-quality.result }} | Linting, formatting, type checking |" >> $GITHUB_STEP_SUMMARY
        echo "| Unit Tests | ${{ needs.test-and-coverage.result }} | Coverage: ${{ env.COVERAGE_THRESHOLD }}% threshold |" >> $GITHUB_STEP_SUMMARY
        echo "| Performance | ${{ needs.performance-benchmark.result }} | Target: <${{ env.PERFORMANCE_TARGET_MS }}ms |" >> $GITHUB_STEP_SUMMARY
        echo "| Research Validation | ${{ needs.research-validation.result }} | 33% accuracy, 65% diversity, 45% novelty |" >> $GITHUB_STEP_SUMMARY
        echo "| Security Scan | ${{ needs.security-scan.result }} | Bandit + Safety vulnerability scanning |" >> $GITHUB_STEP_SUMMARY
        echo "| Docker Build | ${{ needs.build-image.result }} | Multi-platform image with SBOM |" >> $GITHUB_STEP_SUMMARY
        echo "| Staging Deploy | ${{ needs.deploy-staging.result }} | Automated deployment and validation |" >> $GITHUB_STEP_SUMMARY
        echo "| Production Deploy | ${{ needs.deploy-production.result }} | Canary deployment strategy |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [[ "${{ github.ref }}" == refs/tags/* ]]; then
          echo "üéâ **Release ${{ github.ref_name }} deployed successfully!**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üì¶ Deployment Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Version**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployed by**: ${{ github.actor }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Staging**: ‚úÖ Deployed and validated" >> $GITHUB_STEP_SUMMARY
          echo "- **Production**: ‚úÖ Canary deployment successful" >> $GITHUB_STEP_SUMMARY
          echo "- **PyPI**: ‚úÖ Package published" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
          echo "‚úÖ **Main branch validation completed**" >> $GITHUB_STEP_SUMMARY
        elif [[ "${{ github.ref }}" == "refs/heads/develop" ]]; then
          echo "üöÄ **Development branch deployed to staging**" >> $GITHUB_STEP_SUMMARY
        else
          echo "üîç **Pull request validation completed**" >> $GITHUB_STEP_SUMMARY
        fi
